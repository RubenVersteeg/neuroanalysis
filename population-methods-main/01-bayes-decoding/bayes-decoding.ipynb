{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian decoding of neural activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### ABOUT THIS LESSON \n",
    "---\n",
    "\n",
    "Lesson time: 60 m   \n",
    "Contributors: Federico Stella, Davide Spalla\n",
    "\n",
    "**In this lesson you will learn:**\n",
    "- What a bayesian decoder is and how to use it\n",
    "- How to decode the position of an animal running in one and two dimensions\n",
    "- How to use decoding techniques to investigate neural activity during sleep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    " \n",
    "In this lesson we will take a look at some techniques aimed at \"reading\" neural activity and allowing us to interpret its content and to evaluate how much information it carries about a specific set of stimuli, conditions or states. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes decoding\n",
    "---\n",
    " Bayesian decoders are a simple but powerful tool for decoding the value of a stimulus from the observed neural activity.\n",
    " Let $P(s)$ denote the probability of presentation of stimulus $s$ (belonging to a set $S$) and $P(r|s)$ denote the conditional probability of obtaining a population response $r$ (out of a response set $R$) when stimulus s is presented. Using Bayes' theorem, we can write the probability of the stimulus given the response:\n",
    "\n",
    " $$P(s|r) = \\frac{P(r|s)P(s)}{P(r)}$$\n",
    "\n",
    "This equation gives the posterior probability of a response $r$, given that a stimulus $s$ was presented. \n",
    "Bayesian decoding calculates from this posterior probability distribution a single prediction of the most likely stimulus, i.e. the maximum of the posterior distribution. \n",
    "\n",
    "In the case of a neural population, $P(r|s)$ lives in an $N$ dimensional space, where $N$ is the number of observed neurons, and its estimation can be a daunting problem. We can, however, make the simplifying assumption that the activity of each neuron is independent.In this case, we can factorize likelihood as:\n",
    "\n",
    "$$P(r|s)=\\prod_{i=1}^{N}P(r_{i}|s)$$\n",
    "\n",
    "Note that, since we are generally interested in finding the maximum of the posterior distribtuion, we often do not need to evaluate the denominator $P(r)$ (which is usually difficult to calculate).\n",
    "Moreover, if the prior $P(s)$ is flat (each stimulus value is equiprobable a priori), the problem simplifies further, and we are left with the follwing expression for the decoded stimulus value:\n",
    "\n",
    "$$s^{*}=argmax_{s}(\\prod_{i=1}^{N}P(r_{i}|s))$$\n",
    "\n",
    "To compute this value, all we need is to estimate the probability of observing a certain response (usually a number of spikes in a given time interval, i.e. the firing rate) given the stimulus, for each of our neurons.\n",
    "This quantity, estimated throughout the stimulus support, is nothing but the tuning curve of the neuron.\n",
    "We'll now take a look on how we can use this procedure to decode the position of a running animal from it's place cells, and how we can exploit some mild assumptions on the neural population to make this procedure faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding position on a linear track\n",
    "---\n",
    "\n",
    "As an example, let's look at how we can decode the position of the animal on a linear track from the activity of its hippocampal place cells. We will start from simulated data for a clearer example, then move on to some real data.\n",
    "For the simulated data, well' use some generated with the code you can find in the lesson on [place cells]() of this course.\n",
    "\n",
    "First, let's import the data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"code\"))\n",
    "from utils import download_data\n",
    "\n",
    "sns.set_theme(context='notebook',style='white',font_scale=1.5,\n",
    "              rc = {'axes.spines.top':False,'axes.spines.right':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#download lesson data\n",
    "download_data('https://surfdrive.surf.nl/files/index.php/s/gOwG6DKD7IpkPze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code: data import\n",
    "data_file = 'data/linear_track_data.pickle'\n",
    "with open(data_file, 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "\n",
    "x,t,spikes = data['x'],data['t'],data['spikes']\n",
    "track_length = data['track_length']\n",
    "fps = data['fps'] \n",
    "n_cells = len(spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data: we can plot the position as a funtion of time, and superimpose the points in which spikes are emitted by each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_unit(i):\n",
    "    plt.plot(t, x)\n",
    "    plt.plot(spikes[i], np.interp(spikes[i], t, x), 'r.')\n",
    "    \n",
    "interact(plot_unit, i = widgets.IntSlider(min=0, max=(n_cells-1), value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "\n",
    "### Interactive plotting with ipywidgets\n",
    "\n",
    "In the cell above the use of [`interact`](https://ipywidgets.readthedocs.io/en/7.6.2/examples/Using%20Interact.html) (from [ipywidgets](https://ipywidgets.readthedocs.io/en/stable/)) to make an interactive plot so that we quickly explore the behavior of all cells. `ipywidgets` offers quite a lot of methods to build simple interactive plots, and can be very useful to explore complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, many cells have place-related activity (their firing concentrates around certain positions in the track). We can use the information provided by the neural population to decode the animals position, with our bayesian decoding framework.  \n",
    "To perform bayesian decoding, we need to estimate $P(r_{i}|s)$. This is done by computing the firing rate maps of each cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we compute the poistion at which each spike was emitted\n",
    "spike_positions = [np.interp(s, t, x) for s in spikes]\n",
    "space_bins = np.arange(0., track_length, 5.) # binning in bins of 5 cms\n",
    "\n",
    "# we compute histograms for each cell\n",
    "spikes_hist= [np.histogram(s, space_bins)[0] for s in spike_positions]\n",
    "spikes_hist = np.asarray(spikes_hist)\n",
    "\n",
    "# we also need an \"occupancy histogram\" in order to normalize the firing rates maps \n",
    "occupancy = np.histogram(x, space_bins)[0] /  fps\n",
    "\n",
    "firing_rate_maps = spikes_hist / occupancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's look at the ratemaps\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(firing_rate_maps, cmap='inferno', extent = [0, 200, 0, n_cells])\n",
    "plt.xlabel('location (cm)')\n",
    "plt.ylabel('cell #')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we bin the spikes in 33 ms windows (the same temporal resolution of the behaviour). This will give us a snapshot of the neural activity for each position of the animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spikes_count= [np.histogram(s,t)[0] for s in spikes]\n",
    "spikes_count = np.asarray(spikes_count).T # we transpose the matrix to have the more familiar (samples x features) shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the equations we derived, to decode the position of the animal at each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code decoding\n",
    "from scipy.stats import poisson\n",
    "\n",
    "true_x = x[:-1] # get rid of last timepoint to have same length as binned spikes\n",
    "decoding_times = t[:-1]\n",
    "\n",
    "x_decoded = np.zeros_like(true_x)\n",
    "\n",
    "for t_bin in tqdm(range(len(decoding_times))):\n",
    "    if sum(spikes_count[t_bin,:])>0: # Check if the time window contains spikes\n",
    "        posterior = np.empty(firing_rate_maps.shape[-1])\n",
    "\n",
    "        for i in range(len(posterior)):\n",
    "            # Note that we work with log so that we can sum probabilities\n",
    "            # instead of multiplying them \n",
    "            #posterior[i] = sum(np.log(poisson.pmf(spikes_count[t_bin,:],firing_rate_maps[:,i]/fps)+pow(1,-15)))\n",
    "            posterior[i] = sum(poisson.logpmf(spikes_count[t_bin,:],firing_rate_maps[:,i]/fps)+pow(1,-15))\n",
    "\n",
    "\n",
    "        x_decoded[t_bin] = space_bins[np.argmax(posterior)]\n",
    "    else:\n",
    "        x_decoded[t_bin] = np.nan   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_decoded,label= 'decoded x')\n",
    "plt.plot(true_x,label = 'true x')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# error distribution\n",
    "mse = np.sqrt((true_x-x_decoded)**2)\n",
    "sns.histplot(mse)\n",
    "plt.axvline(x = np.nanmedian(mse),c='r')\n",
    "print(f'Median error: {np.nanmedian(mse)} cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decoder can predict the animal position with a median error around 6 cm. How does this change with sample size, number of cell, and noise? You can explore the effect of these and other features in the [exercises](./exercises.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Vectorization of the bayes decoder\n",
    "Above we calculated the (log) posterior distributions by looping both on the time bins and the spatial bins.  \n",
    "This results in a code that is quite slow, but we can do better: we can leverage the analytical expression of the posterior distirbution, and re-write the code using linear algebra, to obtain a much faster decoder.  \n",
    "\n",
    "First, since the probability $P(n_{i}|x)$ of observing $n_{i}$ spikes from neuron $i$, given a position x, is assumed to be poissonian, we can write it as:\n",
    "\n",
    "$$P(n_{i}|x) = \\frac{(\\tau f_{i}(x))^{n_{i}}}{n_{i}!}exp(-\\tau f_{i}(x))$$\n",
    "\n",
    "Where $f_{i}(x)$ is the average firing rate of the neuron in position $x$ (i.e. the firing rate map value).\n",
    "For the whole population we then have:\n",
    "\n",
    "$$P(n|x)=\\prod_{i=1}^{N}P(n_{i}|x)= \\prod_{i=1}^{N} \\frac{(\\tau f_{i}(x))^{n_{i}}}{n_{i}!}\\exp(-\\tau f_{i}(x)) $$\n",
    "\n",
    "And this gives us the posterior:\n",
    "\n",
    "$$P(x|n)=CP(x) \\prod_{i=1}^{N} \\frac{(\\tau f_{i}(x))^{n_{i}}}{n_{i}!}\\exp(-\\tau f_{i}(x)) $$\n",
    "\n",
    "Where $C$ is a normalization constant (that we do not need to calculate in our maximization procedure) and $P(x)$ is the positional prior.\n",
    "\n",
    "Taking the logarithm of the posterior, we obtain:\n",
    "\n",
    "$$\\log(P(x|\\textbf{n}))= \\sum_{i=1}^{N} \\left[ n_{i}\\log(f_{i}(x)) -\\tau f_{i}(x) \\right]+\\log(\\tau) +\\log(n!) + C + P(x)$$\n",
    "\n",
    "\n",
    "We can rewritre the posterior calculation using the matrices `Sp` (n_time_bins x n_space_bins), `Rm` (n_cells,n_space_bins) and `Pr` (1 x n_space_bins):\n",
    "\n",
    "```\n",
    "Pt = Sp @ np.log(Rm) - dt*np.sum(Rm, axis=0) + np.log(Pr)\n",
    "```  \n",
    "\n",
    "With $dt=1/fps$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prior = occupancy / sum(occupancy)\n",
    "epsilon = pow(1,-10)\n",
    "log_posteriors = spikes_count @ np.log(firing_rate_maps+epsilon) - (1./fps)*np.sum(firing_rate_maps, axis=0) #+ np.log(prior + epsilon)\n",
    "\n",
    "x_parallel = [space_bins[np.argmax(P)] for P in log_posteriors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x_parallel,label= 'decoded x')\n",
    "plt.plot(true_x,label = 'true x')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# error distribution\n",
    "mse = np.sqrt((true_x-x_parallel)**2)\n",
    "sns.histplot(mse)\n",
    "plt.axvline(x = np.nanmedian(mse),c='r')\n",
    "print(f'Median error: {np.nanmedian(mse)} cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we obtain the same results (with some minor difference due to numerical effects), in a small fraction of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "\n",
    "### Timing function exectutions in pyhton\n",
    "Python offers many tools to benchmark the execution time of your code.\n",
    "Check out the %timeit [magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html) for jupyter, or this thread on stack oveflow on [measuring time of funtions](https://stackoverflow.com/questions/5478351/python-time-measure-function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential reactivation during sleep\n",
    "---\n",
    "\n",
    "The use of decoding methods is not limited to measure the amount of information that a neural population carries about a specific set of stimuli, or to predict what stimulus is present at a given time. It is extremely useful to interpret the content of neural activity when no stimulus is present and such activity is spontaneously generated by the network.\n",
    "\n",
    "In the case of the hippocampus it has been extensively observed that during rest periods (either while the animal is standing still, waiting somewhere, or while it is sleeping) place cells reactivate specific patterns of activity corresponding to sequences of locations in the environment. This phenomenon, called \"replay\" is thought to be critical for the formation of memories, for the acquisition of novel knowledge and for the reorganization of different sorts of information in the brain (You can read [this review](https://www.sciencedirect.com/science/article/abs/pii/S0166223610000172?via%3Dihub) for an overview on this field of research).    \n",
    "\n",
    "\n",
    "Here we want to simulate the occurrence of such reactivation events. Some of them will actually contain sequences, that is, the neural activity will represent a series of locations in the order they appear on the linear track. Other reactivation events will instead contain activity representing locations on the linear track, but these locations will be randomly drawn, so they will have no clear ordering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate data \n",
    "\n",
    "n_events = 200 # number of reactivation events\n",
    "event_duration = 100 # in bins\n",
    "sampling_rate = 100 # sampling rate \n",
    "t_react = np.arange(0,100)\n",
    "noise_x_react=5; # Noise in the reactivation of the sequence\n",
    "noise_t_react=5; # Noise in the timing of the spikes \n",
    "noise_firing_rate = 0.1 # the baseline noise firing rate\n",
    "\n",
    "\n",
    "reactivation_events = np.zeros((n_events,event_duration))\n",
    "spikes_react = np.zeros((n_events,n_cells,event_duration))\n",
    "\n",
    "for event in range(n_events):\n",
    "    if(event<=n_events//2):\n",
    "    #Generate \"real\" sequences for the first half of events\n",
    "        x_start = np.random.uniform(0,track_length) # Starting point\n",
    "        x_end = np.random.uniform(0,track_length) # Ending point\n",
    "        x_react = np.linspace(x_start,x_end,event_duration) \\\n",
    "            +np.random.normal(0,noise_x_react,size=event_duration)\n",
    "\n",
    "    else:\n",
    "        #Pick locations randomly for the second half \n",
    "        x_react = np.random.uniform(0,track_length,size=event_duration);\n",
    "\n",
    "    x_react[x_react<0]=0;\n",
    "    x_react[x_react>track_length]=track_length\n",
    "    \n",
    "    #store reactivation sequence\n",
    "    reactivation_events[event,:] = x_react\n",
    "\n",
    "    \n",
    "    # Generate spikes according to the location being reactivated in this event\n",
    "    \n",
    "    for i in range(n_cells):\n",
    "        binned_x = np.digitize(x_react,bins=np.linspace(0,track_length,firing_rate_maps.shape[-1]))-1\n",
    "        inst_rate = firing_rate_maps[i,binned_x] + np.random.normal(0,noise_firing_rate,size=len(binned_x))\n",
    "        inst_rate[inst_rate<0] = 0\n",
    "        spikes_loc = np.where(np.random.poisson(inst_rate/sampling_rate)>0)\n",
    "        spikes_loc = spikes_loc + np.round(np.random.normal(0,noise_t_react,size=len(spikes_loc)))\n",
    "        spikes_loc = spikes_loc[np.logical_and(spikes_loc>0,spikes_loc<event_duration)]\n",
    "        spikes_react[event,i,spikes_loc.astype(int)] = 1\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the sequence, we will plot the activity after sorting the cells according to the place field center (in this case defined as the peak location of their firing rate map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfc_idxs = [np.argmax(rate_map) for rate_map in firing_rate_maps] \n",
    "sorted_idxs = np.argsort(pfc_idxs)\n",
    "\n",
    "\n",
    "event = 50\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Sequence event')\n",
    "plt.imshow(spikes_react[event,sorted_idxs,:], cmap='Greys', extent = [0, 200, 0, n_cells])\n",
    "plt.xlabel('location (cm)')\n",
    "plt.ylabel('cell #')\n",
    "\n",
    "event = 150\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Non-sequence event')\n",
    "plt.imshow(spikes_react[event,sorted_idxs,:], cmap='Greys', extent = [0, 200, 0, n_cells])\n",
    "plt.xlabel('location (cm)')\n",
    "plt.ylabel('cell #')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use bayesian decoding to detect reactivated sequences among these events.\n",
    "To do so, we fit a straight line to the decoded locations, taken in order of observation time. The slope of the line will around zero for random reactivations, that do not progress during time, but it will be positive (or negative) for sequences in which the decoded location increases (or decreases) in time on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_window = 10 # number of bins to aggregate during decoding\n",
    "\n",
    "reactivation_slope = np.zeros(n_events)\n",
    "\n",
    "for event in range(n_events):\n",
    "\n",
    "    event_spikes = spikes_react[event]\n",
    "    # First we bin the events in windows of 10 bins\n",
    "    spikes_sampled = np.zeros((n_cells,event_spikes.shape[1]//time_window))\n",
    "    # We generate a new spike matrix with the re-sized window\n",
    "    for t_r in range(1,event_spikes.shape[1]//time_window):\n",
    "        spikes_sampled[:,t_r] = np.sum(event_spikes[:,(t_r-1)*time_window :(t_r)*time_window],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to do: bayesian decoding\n",
    "t_resize = 10 # We use spikes from multiple time windows for the decoding\n",
    "\n",
    "reactivation_slopes = np.zeros(n_events)\n",
    "reactivation_pvalues = np.zeros(n_events)\n",
    "\n",
    "for event in range(n_events):\n",
    "\n",
    "    event_spikes = spikes_react[event]\n",
    "    spikes_sampled = np.zeros((n_cells,event_spikes.shape[1]//t_resize))\n",
    "\n",
    "    # We generate a new spike matrix with the re-sized window\n",
    "    for t_r in range(1,event_spikes.shape[1]//t_resize):\n",
    "        spikes_sampled[:,t_r] = np.sum(event_spikes[:,(t_r-1)*t_resize :(t_r)*t_resize],axis=1)\n",
    "\n",
    "\n",
    "    # We then perform decoding on the aggregated spikes\n",
    "    x_decoded = np.zeros(spikes_sampled.shape[1])\n",
    "\n",
    "    for t_bin in range(spikes_sampled.shape[1]):\n",
    "\n",
    "        if sum(spikes_count[t_bin,:])>0: # Check if the time window contains spikes\n",
    "\n",
    "            posterior = np.empty(firing_rate_maps.shape[-1])\n",
    "            for i in range(len(posterior)):\n",
    "                posterior[i] = sum(poisson.logpmf(spikes_sampled[:,t_bin],firing_rate_maps[:,i]*t_resize/fps)+pow(1,-15))\n",
    "\n",
    "            x_decoded[t_bin] = space_bins[np.argmax(posterior)]\n",
    "\n",
    "        else:\n",
    "            x_decoded[t_bin] = np.nan   \n",
    "\n",
    "        # We fit a line to the decoded positions, and save the slope\n",
    "        slope,_ = np.polyfit(np.arange(len(x_decoded)),x_decoded,deg=1)\n",
    "        reactivation_slopes[event] = slope\n",
    "        # And calculate the pvalue of the pearson correlation\n",
    "        corr = pearsonr(np.arange(len(x_decoded)),x_decoded)\n",
    "        reactivation_pvalues[event] = corr[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the distribution of slopes and correlation pvalues for the events in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(reactivation_slopes,bins=20)\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(reactivation_pvalues,bins=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method we can detect a forward or backward sequence in our reactivation events. The calculation of the correlation p-value also allows us to assign a statistical confidence on how strongly the activity was sequentially organized.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Key points \n",
    "\n",
    "- Naive Bayes decoders use bayes' formula to estimate the probability of observing a stimulus given a certain pattern of neural responses\n",
    "- In its simplest form, this algorithms relies on the assumption of *flat stimulus prior*, *and independence between neurons*\n",
    "- This decoder can be used to recover the animal position during 1D and 2D navigation\n",
    "- Decoding approaches can be used to investigate spontaneous neural activity during sleep or rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### References and resources\n",
    "\n",
    "**Books & papers**\n",
    "* Review on neural decoding: https://www.nature.com/articles/nrn2578\n",
    "* Review on information processing in neural populations: https://www.nature.com/articles/35039062 \n",
    "* Review on hippocampal replay and reactivation: https://www.sciencedirect.com/science/article/abs/pii/S0166223610000172?via%3Dihub \n",
    "\n",
    "**Websites & blogposts**\n",
    "\n",
    "**Software**\n",
    "* A python package for neural decoding: https://github.com/KordingLab/Neural_Decoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "You can find the exercises for this lessons in [exercises.ipynb](./exercises.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec757111aa82fc412dab5a41ba1a33fdb6db5c8112df3ff06fec0dbff050b412"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
